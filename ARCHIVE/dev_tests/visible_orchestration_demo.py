"""
Visible ARCH-CTO Orchestration Demo - See what's actually happening!

This script demonstrates the orchestration workflow with detailed visibility:
1. ARCH-CTO (Claude) assigns task to Backend Agent
2. Backend Agent implements the solution with REAL code generation
3. ARCH-CTO reviews the code and provides feedback
4. Show the complete workflow with full output
"""

import asyncio
import logging

from orchestration.arch_cto_orchestrator import create_arch_cto_orchestrator

from agents.base.types import Priority, TaskType
from core.routing.providers.mock_provider import MockConfig
from enhanced_mock_provider import EnhancedMockProvider

# Setup detailed logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


async def setup_orchestrator_with_mock_llm():
    """Create orchestrator with configured mock LLM provider."""
    print("ğŸ”§ Setting up ARCH-CTO Orchestrator with Mock LLM Provider...")

    # Create orchestrator
    orchestrator = await create_arch_cto_orchestrator()

    # Get the backend agent's LLM router
    backend_agent = orchestrator.active_agents["backend"]
    router = backend_agent.router

    # Create and register enhanced mock provider
    mock_config = MockConfig(
        provider_name="enhanced_mock",
        response_delay=0.5,  # 500ms delay to simulate real API
        failure_rate=0.0     # No failures for demo
    )

    enhanced_mock_provider = EnhancedMockProvider(
        config=mock_config
    )

    # Register the provider with the router
    router.register_provider("enhanced_mock", enhanced_mock_provider)

    print("âœ… Mock LLM Provider registered successfully!")
    print(f"   Router now has {len(router.providers)} provider(s)")

    return orchestrator


async def show_detailed_orchestration():
    """Run orchestration with full visibility."""

    print("ğŸ¯ " + "="*80)
    print("   VISIBLE ARCH-CTO ORCHESTRATION DEMO")
    print("   See exactly what happens when Claude orchestrates coding agents!")
    print("ğŸ¯ " + "="*80)
    print()

    # Setup orchestrator with mock LLM
    orchestrator = await setup_orchestrator_with_mock_llm()
    print()

    # Define our test task
    task_description = """
Create a FastAPI endpoint for a user authentication system:

Requirements:
- POST /auth/login endpoint
- Accept JSON with: email, password
- Validate email format and password strength
- Return JWT token on success
- Include proper error handling for invalid credentials
- Write comprehensive unit tests
- Follow FastAPI best practices and security guidelines

This should be production-ready authentication code.
"""

    print("ğŸ“‹ TASK ASSIGNMENT & EXECUTION")
    print("-" * 50)
    print("ğŸ¯ Task: Creating FastAPI authentication endpoint")
    print(f"ğŸ“ Description: {task_description.strip()}")
    print()

    # Assign task
    print("ğŸ‘¥ Assigning to Backend Developer Agent...")
    task_id = await orchestrator.assign_task(
        task_description=task_description,
        task_type=TaskType.CODE_GENERATION,
        agent_type="backend",
        complexity=7,  # Higher complexity for auth
        priority=Priority.HIGH,
        metadata={
            "endpoint": "/auth/login",
            "method": "POST",
            "requires_security": True,
            "requires_tests": True,
            "auth_type": "JWT"
        }
    )

    print(f"âœ… Task assigned with ID: {task_id}")
    print()

    # Execute task with detailed monitoring
    print("âš™ï¸ BACKEND AGENT EXECUTION")
    print("-" * 40)
    print("ğŸ¤– Backend Agent is thinking and generating code...")
    print("ğŸ’­ Agent context: FastAPI specialist with security expertise")

    result = await orchestrator.execute_task(task_id)

    print("âœ¨ Code generation completed!")
    print(f"   â±ï¸  Execution time: {result.execution_time:.2f}s")
    print(f"   ğŸ”¤ Tokens used: {result.tokens_used}")
    print(f"   ğŸ’° Cost: ${result.cost:.4f}")
    print(f"   ğŸ§  Model: {result.model_used}")
    print(f"   ğŸ­ Provider: {result.provider_used}")
    print(f"   âœ… Success: {result.success}")
    print()

    # Show the actual generated code
    if result.output:
        print("ğŸ’» GENERATED CODE")
        print("-" * 20)
        print("ğŸ“„ Here's what the Backend Agent created:")
        print()
        print("ğŸ”¹" + "-" * 78 + "ğŸ”¹")
        print(result.output)
        print("ğŸ”¹" + "-" * 78 + "ğŸ”¹")
        print()
    else:
        print("âš ï¸  No code output generated")
        print()

    # Code Review by ARCH-CTO
    print("ğŸ” ARCH-CTO CODE REVIEW")
    print("-" * 35)
    print("ğŸ‘¨â€ğŸ’¼ ARCH-CTO (Claude) reviewing the Backend Agent's work...")

    review = await orchestrator.review_task(task_id)

    print("ğŸ“Š Review Results:")
    print(f"   ğŸ† Quality Score: {review.quality_score}/10")
    print(f"   âš–ï¸  Decision: {review.outcome.value.replace('_', ' ').title()}")
    print(f"   ğŸ”„ Needs Revision: {review.requires_revision}")
    print(f"   ğŸ“ Summary: {review.summary}")
    print()

    if review.detailed_feedback:
        print("ğŸ“‹ Detailed Feedback:")
        for i, feedback in enumerate(review.detailed_feedback, 1):
            print(f"   {i}. {feedback}")
        print()

    if review.security_issues:
        print("ğŸš¨ Security Issues Found:")
        for i, issue in enumerate(review.security_issues, 1):
            print(f"   {i}. {issue}")
        print()

    # Show final decision
    if review.requires_revision:
        print("ğŸ”„ REVISION REQUIRED")
        print("-" * 25)
        print("ğŸ’¡ The ARCH-CTO has identified areas for improvement.")
        print("ğŸ”§ In a real scenario, this would trigger another development cycle.")
        print("ğŸ“ˆ This iterative process ensures high-quality code delivery.")
    else:
        print("âœ… CODE APPROVED!")
        print("-" * 20)
        print("ğŸ‰ The Backend Agent's code meets ARCH-CTO quality standards!")
        print("ğŸš€ Code is ready for deployment to staging environment.")
        print("ğŸ“Š Quality metrics passed all thresholds.")

    print()

    # Show orchestration metrics
    print("ğŸ“Š ORCHESTRATION ANALYTICS")
    print("-" * 35)

    # Task status
    task_status = orchestrator.get_task_status(task_id)
    print("ğŸ“ˆ Task Metrics:")
    print(f"   ğŸ†” Task ID: {task_id}")
    print(f"   ğŸ“Š Status: {task_status['status']}")
    print(f"   ğŸ¯ Complexity: {task_status['complexity']}/10")
    print(f"   â° Estimated time: {task_status['estimated_hours']:.1f}h")
    if task_status.get('actual_hours'):
        print(f"   â±ï¸  Actual time: {task_status['actual_hours']:.3f}h")
    print(f"   ğŸ”„ Revision cycles: {task_status['revision_count']}")
    print()

    # Orchestrator metrics
    metrics = orchestrator.get_orchestration_metrics()
    print("ğŸ¯ Orchestrator Performance:")
    print(f"   ğŸ“ Total tasks: {metrics.total_tasks}")
    print(f"   âœ… Completed: {metrics.completed_tasks}")
    print(f"   â° Avg completion: {metrics.average_completion_time:.2f}h")
    print(f"   ğŸ”„ Avg review cycles: {metrics.average_review_cycles:.1f}")

    if metrics.quality_trends:
        avg_quality = sum(metrics.quality_trends) / len(metrics.quality_trends)
        print(f"   ğŸ† Avg quality score: {avg_quality:.1f}/10")
    print()

    # Agent status
    backend_agent = orchestrator.active_agents["backend"]
    agent_status = backend_agent.get_status()
    print("ğŸ¤– Backend Agent Status:")
    print(f"   ğŸ†” Agent ID: {agent_status['agent_id'][:8]}...")
    print(f"   ğŸ“Š State: {agent_status['lifecycle_state']}")
    print(f"   âœ… Tasks completed: {agent_status['tasks_completed']}")
    print(f"   ğŸ“ˆ Success rate: {agent_status['success_rate']:.1%}")
    print(f"   ğŸ’° Total cost: ${agent_status['total_cost']:.4f}")
    print(f"   â±ï¸  Avg execution time: {agent_status['average_execution_time']:.2f}s")
    print()

    # Cleanup
    await orchestrator.shutdown()

    # Summary
    print("ğŸ¯ DEMO SUMMARY")
    print("-" * 20)
    print("âœ¨ Successfully demonstrated:")
    print("   ğŸ¯ Direct ARCH-CTO orchestration model")
    print("   ğŸ¤– Backend Agent code generation")
    print("   ğŸ’» Real FastAPI code output")
    print("   ğŸ” Automated code review process")
    print("   ğŸ“Š Quality scoring and feedback")
    print("   ğŸ”„ Revision workflow management")
    print("   ğŸ“ˆ Comprehensive metrics tracking")
    print()
    print("ğŸš€ The orchestration system is working beautifully!")
    print("ğŸ’¡ Claude successfully acts as ARCH-CTO managing coding agents.")


async def show_agent_thinking_process():
    """Demonstrate the agent's thinking process."""
    print("\nğŸ§  AGENT THINKING PROCESS")
    print("-" * 35)
    print("Let me show you what happens inside the Backend Agent's mind...")
    print()

    orchestrator = await setup_orchestrator_with_mock_llm()
    backend_agent = orchestrator.active_agents["backend"]

    # Show agent capabilities
    print("ğŸ¯ Agent Identity:")
    print(f"   ğŸ·ï¸  Name: {backend_agent.config.name}")
    print(f"   ğŸ¢ Type: {backend_agent.config.agent_type.value}")
    print(f"   ğŸ› ï¸  Capabilities: {[cap.value for cap in backend_agent.config.capabilities]}")
    print()

    # Show routing preferences
    print("ğŸ§  LLM Routing Preferences:")
    print(f"   ğŸ¯ Strategy: {backend_agent.config.default_routing_strategy.value}")
    print(f"   ğŸ”¤ Max tokens: {backend_agent.config.max_tokens}")
    print(f"   ğŸŒ¡ï¸  Temperature: {backend_agent.config.temperature}")
    print()

    # Show knowledge base
    print("ğŸ“š Knowledge Areas:")
    print(f"   ğŸ”§ Expertise: {backend_agent.expertise_areas}")
    print()

    print("ğŸ“‹ Quality Standards:")
    for standard, description in backend_agent.quality_standards.items():
        print(f"   â€¢ {standard}: {description}")
    print()

    await orchestrator.shutdown()


if __name__ == "__main__":
    print("ğŸ¯ Starting Visible ARCH-CTO Orchestration Demo...")
    print()

    # Run the main demo
    asyncio.run(show_detailed_orchestration())

    # Show agent thinking process
    asyncio.run(show_agent_thinking_process())

    print("\nğŸ‰ Demo complete! You can now see exactly how orchestration works.")
